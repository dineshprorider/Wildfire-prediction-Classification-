{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1649d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopandas\n",
      "  Obtaining dependency information for geopandas from https://files.pythonhosted.org/packages/c4/64/7d344cfcef5efddf9cf32f59af7f855828e9d74b5f862eddf5bfd9f25323/geopandas-1.0.1-py3-none-any.whl.metadata\n",
      "  Downloading geopandas-1.0.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: numpy>=1.22 in ./anaconda3/lib/python3.11/site-packages (from geopandas) (1.24.3)\n",
      "Collecting pyogrio>=0.7.2 (from geopandas)\n",
      "  Obtaining dependency information for pyogrio>=0.7.2 from https://files.pythonhosted.org/packages/8d/2c/c761e6adeb81bd4029a137b3240e7214a8c9aaf225883356196afd6ef9d8/pyogrio-0.10.0-cp311-cp311-macosx_12_0_arm64.whl.metadata\n",
      "  Downloading pyogrio-0.10.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: packaging in ./anaconda3/lib/python3.11/site-packages (from geopandas) (23.1)\n",
      "Requirement already satisfied: pandas>=1.4.0 in ./anaconda3/lib/python3.11/site-packages (from geopandas) (2.0.3)\n",
      "Collecting pyproj>=3.3.0 (from geopandas)\n",
      "  Obtaining dependency information for pyproj>=3.3.0 from https://files.pythonhosted.org/packages/2d/4d/610fe2a17de71b4fe210af69ce25f2d65379ba0a48299129894d0d0988ee/pyproj-3.7.0-cp311-cp311-macosx_14_0_arm64.whl.metadata\n",
      "  Downloading pyproj-3.7.0-cp311-cp311-macosx_14_0_arm64.whl.metadata (31 kB)\n",
      "Collecting shapely>=2.0.0 (from geopandas)\n",
      "  Obtaining dependency information for shapely>=2.0.0 from https://files.pythonhosted.org/packages/37/63/e182e43081fffa0a2d970c480f2ef91647a6ab94098f61748c23c2a485f2/shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./anaconda3/lib/python3.11/site-packages (from pandas>=1.4.0->geopandas) (2023.3)\n",
      "Requirement already satisfied: certifi in ./anaconda3/lib/python3.11/site-packages (from pyogrio>=0.7.2->geopandas) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.5 in ./anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.4.0->geopandas) (1.16.0)\n",
      "Downloading geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.6/323.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyogrio-0.10.0-cp311-cp311-macosx_12_0_arm64.whl (15.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyproj-3.7.0-cp311-cp311-macosx_14_0_arm64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: shapely, pyproj, pyogrio, geopandas\n",
      "Successfully installed geopandas-1.0.1 pyogrio-0.10.0 pyproj-3.7.0 shapely-2.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be489d7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "DataSourceError",
     "evalue": "/Users/dinesh/Documents/College/DATASET/wildfire.shp: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataSourceError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 81\u001b[0m\n\u001b[1;32m     78\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/dinesh/Documents/College/DATASET/wildfire.shp\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Replace with your actual file path\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m geospatial_data \u001b[38;5;241m=\u001b[39m load_data(file_path)\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Specify the target column and columns to drop\u001b[39;00m\n\u001b[1;32m     84\u001b[0m target_column \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwildfire_risk\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(file_path):\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Load geospatial data using GeoPandas.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    :param file_path: Path to the geospatial dataset file\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    :return: GeoDataFrame\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     data \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mread_file(file_path)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:294\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, columns, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m             from_bytes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[1;32m    295\u001b[0m         filename, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, columns\u001b[38;5;241m=\u001b[39mcolumns, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    296\u001b[0m     )\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_file_like(filename):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/geopandas/io/file.py:547\u001b[0m, in \u001b[0;36m_read_file_pyogrio\u001b[0;34m(path_or_bytes, bbox, mask, rows, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore_fields\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keywords are deprecated, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    540\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future release. You can use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    543\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    544\u001b[0m     )\n\u001b[1;32m    545\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minclude_fields\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pyogrio\u001b[38;5;241m.\u001b[39mread_dataframe(path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyogrio/geopandas.py:265\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, fid_as_index, use_arrow, on_invalid, arrow_to_pandas_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m use_arrow:\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# For arrow, datetimes are read as is.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# For numpy IO, datetimes are read as string values to preserve timezone info\u001b[39;00m\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;66;03m# as numpy does not directly support timezones.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime_as_string\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m result \u001b[38;5;241m=\u001b[39m read_func(\n\u001b[1;32m    266\u001b[0m     path_or_buffer,\n\u001b[1;32m    267\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[1;32m    268\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    269\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    270\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[1;32m    271\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mgdal_force_2d,\n\u001b[1;32m    272\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[1;32m    273\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[1;32m    274\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    275\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[1;32m    276\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    277\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[1;32m    278\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[1;32m    279\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[1;32m    280\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mfid_as_index,\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    282\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    285\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pyogrio/raw.py:198\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, mask, fids, sql, sql_dialect, return_fids, datetime_as_string, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read OGR data source into numpy arrays.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mIMPORTANT: non-linear geometry types (e.g., MultiSurface) are converted\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    196\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ogr_read(\n\u001b[1;32m    199\u001b[0m     get_vsi_path_or_buffer(path_or_buffer),\n\u001b[1;32m    200\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[1;32m    201\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    202\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    203\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[1;32m    204\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mforce_2d,\n\u001b[1;32m    205\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[1;32m    206\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    207\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    208\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[1;32m    209\u001b[0m     mask\u001b[38;5;241m=\u001b[39m_mask_to_wkb(mask),\n\u001b[1;32m    210\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[1;32m    211\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[1;32m    212\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[1;32m    213\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mreturn_fids,\n\u001b[1;32m    214\u001b[0m     dataset_kwargs\u001b[38;5;241m=\u001b[39mdataset_kwargs,\n\u001b[1;32m    215\u001b[0m     datetime_as_string\u001b[38;5;241m=\u001b[39mdatetime_as_string,\n\u001b[1;32m    216\u001b[0m )\n",
      "File \u001b[0;32mpyogrio/_io.pyx:1240\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_read\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpyogrio/_io.pyx:220\u001b[0m, in \u001b[0;36mpyogrio._io.ogr_open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDataSourceError\u001b[0m: /Users/dinesh/Documents/College/DATASET/wildfire.shp: No such file or directory"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import geopandas as gpd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load geospatial data\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load geospatial data using GeoPandas.\n",
    "    :param file_path: Path to the geospatial dataset file\n",
    "    :return: GeoDataFrame\n",
    "    \"\"\"\n",
    "    data = gpd.read_file(file_path)\n",
    "    return data\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(data, target_column, drop_columns=None):\n",
    "    \"\"\"\n",
    "    Preprocess geospatial data for modeling.\n",
    "    :param data: GeoDataFrame\n",
    "    :param target_column: Column name for the target variable\n",
    "    :param drop_columns: List of columns to drop\n",
    "    :return: Features and target variables\n",
    "    \"\"\"\n",
    "    if drop_columns:\n",
    "        data = data.drop(columns=drop_columns)\n",
    "    \n",
    "    # Handle missing values\n",
    "    data = data.dropna()\n",
    "\n",
    "    # Separate features and target\n",
    "    X = data.drop(columns=[target_column])\n",
    "    y = data[target_column]\n",
    "    \n",
    "    # Convert categorical data to numerical\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Split the data\n",
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Split data into training and testing sets.\n",
    "    \"\"\"\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Train a classification model\n",
    "def train_model(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a Random Forest Classifier.\n",
    "    :param X_train: Training features\n",
    "    :param y_train: Training target\n",
    "    :return: Trained model\n",
    "    \"\"\"\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model performance on test data.\n",
    "    :param model: Trained model\n",
    "    :param X_test: Testing features\n",
    "    :param y_test: Testing target\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the geospatial dataset\n",
    "    file_path = \"/Users/dinesh/Documents/College/DATASET/wildfire.shp\"  # Replace with your actual file path\n",
    "\n",
    "    # Load the data\n",
    "    geospatial_data = load_data(file_path)\n",
    "\n",
    "    # Specify the target column and columns to drop\n",
    "    target_column = \"wildfire_risk\"\n",
    "    drop_columns = [\"geometry\"]  # Drop geometry for modeling (optional)\n",
    "\n",
    "    # Preprocess the data\n",
    "    X, y = preprocess_data(geospatial_data, target_column, drop_columns)\n",
    "\n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y)\n",
    "\n",
    "    # Train the model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "\n",
    "    # Save the model if needed\n",
    "    # import joblib\n",
    "    # joblib.dump(model, \"wildfire_risk_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6084a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
